{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1b08b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/premkumar/opt/anaconda3/lib/python3.9/site-packages (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/premkumar/opt/anaconda3/lib/python3.9/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cc48c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting uvicorn\n",
      "  Using cached uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: click>=7.0 in /Users/premkumar/opt/anaconda3/lib/python3.9/site-packages (from uvicorn) (8.0.3)\n",
      "Collecting h11>=0.8\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: h11, uvicorn\n",
      "Successfully installed h11-0.14.0 uvicorn-0.22.0\n",
      "Collecting fastapi\n",
      "  Using cached fastapi-0.100.0-py3-none-any.whl (65 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4\n",
      "  Using cached pydantic-2.0.2-py3-none-any.whl (359 kB)\n",
      "Collecting typing-extensions>=4.5.0\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Collecting starlette<0.28.0,>=0.27.0\n",
      "  Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Collecting pydantic-core==2.1.2\n",
      "  Downloading pydantic_core-2.1.2-cp39-cp39-macosx_10_7_x86_64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
      "  Using cached anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.1.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/premkumar/opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi) (3.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/premkumar/opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi) (1.2.0)\n",
      "Installing collected packages: typing-extensions, exceptiongroup, pydantic-core, anyio, annotated-types, starlette, pydantic, fastapi\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 2.2.0\n",
      "    Uninstalling anyio-2.2.0:\n",
      "      Successfully uninstalled anyio-2.2.0\n",
      "Successfully installed annotated-types-0.5.0 anyio-3.7.1 exceptiongroup-1.1.2 fastapi-0.100.0 pydantic-2.0.2 pydantic-core-2.1.2 starlette-0.27.0 typing-extensions-4.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install uvicorn\n",
    "!pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e373376-bc8b-4c62-8018-b5fc19da2b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/12 02:36:09 WARN Utils: Your hostname, Prems-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.29.230 instead (on interface en0)\n",
      "23/07/12 02:36:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/12 02:36:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Model_Building').getOrCreate()\n",
    "df = spark.read.csv('weight_height.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0422604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|Gender|          Height|          Weight|\n",
      "+------+----------------+----------------+\n",
      "|  Male| 73.847017017515|241.893563180437|\n",
      "|  Male|68.7819040458903|  162.3104725213|\n",
      "|  Male|74.1101053917849|  212.7408555565|\n",
      "+------+----------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95c2bf44",
   "metadata": {},
   "source": [
    "# 1.Creating a machine learning model in pyspark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a050bd-2bcf-493a-ae03-0bb18bd17b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1978a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Height: double (nullable = true)\n",
      " |-- Weight: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "370d9061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------------+------------------+\n",
      "|summary|Gender|           Height|            Weight|\n",
      "+-------+------+-----------------+------------------+\n",
      "|  count| 10000|            10000|             10000|\n",
      "|   mean|  null|66.36755975482106|161.44035683283076|\n",
      "| stddev|  null|3.847528120773333|32.108439006519674|\n",
      "|    min|Female| 54.2631333250971|   64.700126712753|\n",
      "|    max|  Male| 78.9987423463896|  269.989698505106|\n",
      "+-------+------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413b5ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|Gender|Height|Weight|\n",
      "+------+------+------+\n",
      "|     0|     0|     0|\n",
      "+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#count null values\n",
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "df.select([count(when (isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "288551f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+----------+\n",
      "|Gender|          Height|          Weight|GenderMale|\n",
      "+------+----------------+----------------+----------+\n",
      "|  Male| 73.847017017515|241.893563180437|       1.0|\n",
      "|  Male|68.7819040458903|  162.3104725213|       1.0|\n",
      "|  Male|74.1101053917849|  212.7408555565|       1.0|\n",
      "|  Male|71.7309784033377|220.042470303077|       1.0|\n",
      "|  Male|69.8817958611153|206.349800623871|       1.0|\n",
      "|  Male|67.2530156878065|152.212155757083|       1.0|\n",
      "|  Male|68.7850812516616|183.927888604031|       1.0|\n",
      "|  Male|68.3485155115879|167.971110489509|       1.0|\n",
      "|  Male| 67.018949662883| 175.92944039571|       1.0|\n",
      "|  Male|63.4564939783664|156.399676387112|       1.0|\n",
      "|  Male|71.1953822829745|186.604925560358|       1.0|\n",
      "|  Male|71.6408051192206|213.741169489411|       1.0|\n",
      "|  Male|64.7663291334055|167.127461073476|       1.0|\n",
      "|  Male|69.2830700967204|189.446181386738|       1.0|\n",
      "|  Male|69.2437322298112|186.434168021239|       1.0|\n",
      "|  Male|67.6456197004212|172.186930058117|       1.0|\n",
      "|  Male|72.4183166259878|196.028506330482|       1.0|\n",
      "|  Male| 63.974325721061| 172.88347020878|       1.0|\n",
      "|  Male|69.6400598997523| 185.98395757313|       1.0|\n",
      "|  Male|67.9360048540095|182.426648013226|       1.0|\n",
      "+------+----------------+----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create label Encoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol='Gender', outputCol='GenderMale')\n",
    "indexer = indexer.fit(df)\n",
    "indexed_df = indexer.transform(df)\n",
    "indexed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36bbfd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#save indexer for test data\n",
    "indexer.save('string_indexer.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ddd731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+----------+--------------------+\n",
      "|Gender|          Height|          Weight|GenderMale|    Independent_feat|\n",
      "+------+----------------+----------------+----------+--------------------+\n",
      "|  Male| 73.847017017515|241.893563180437|       1.0|[73.847017017515,...|\n",
      "|  Male|68.7819040458903|  162.3104725213|       1.0|[68.7819040458903...|\n",
      "|  Male|74.1101053917849|  212.7408555565|       1.0|[74.1101053917849...|\n",
      "|  Male|71.7309784033377|220.042470303077|       1.0|[71.7309784033377...|\n",
      "|  Male|69.8817958611153|206.349800623871|       1.0|[69.8817958611153...|\n",
      "+------+----------------+----------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make the feature  assembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "feature_assembler = VectorAssembler(inputCols=['Height', 'GenderMale'], outputCol='Independent_feat')\n",
    "output = feature_assembler.transform(indexed_df)\n",
    "output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f5d1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving feature assembler\n",
    "feature_assembler.save('feature_assembler.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e6e3852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|    Independent_feat|          Weight|\n",
      "+--------------------+----------------+\n",
      "|[73.847017017515,...|241.893563180437|\n",
      "|[68.7819040458903...|  162.3104725213|\n",
      "|[74.1101053917849...|  212.7408555565|\n",
      "|[71.7309784033377...|220.042470303077|\n",
      "|[69.8817958611153...|206.349800623871|\n",
      "+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#taking only the independent and dependent features\n",
    "finalized_data = output.select('Independent_feat', 'Weight')\n",
    "finalized_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85bf0088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/12 02:36:46 WARN Instrumentation: [22c8c7b8] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/07/12 02:36:47 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/07/12 02:36:47 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "23/07/12 02:36:47 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "train_data, test_data = finalized_data.randomSplit([0.75, 0.25])\n",
    "reg = LinearRegression(featuresCol='Independent_feat',  labelCol='Weight')\n",
    "reg = reg.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bb915bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.974375425670641,19.368737273522576]\n",
      "-244.73773884061185\n"
     ]
    }
   ],
   "source": [
    "print(reg.coefficients)\n",
    "print(reg.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a24b8fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|    Independent_feat|          Weight|\n",
      "+--------------------+----------------+\n",
      "|[54.8737275315254...|78.6066703120237|\n",
      "|[55.336492408949,...|88.3665825783999|\n",
      "|[55.6682021205121...|68.9825300912419|\n",
      "|[56.0786997324948...|94.4883740514904|\n",
      "|[56.4456850266095...|96.6402446637704|\n",
      "+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3af637dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----------------+\n",
      "|    Independent_feat|          Weight|       prediction|\n",
      "+--------------------+----------------+-----------------+\n",
      "|[54.8737275315254...|78.6066703120237|   83.09851043868|\n",
      "|[55.336492408949,...|88.3665825783999|85.86324155022302|\n",
      "|[55.6682021205121...|68.9825300912419|87.84499989944189|\n",
      "|[56.0786997324948...|94.4883740514904|90.29746674476783|\n",
      "|[56.4456850266095...|96.6402446637704|92.48997466750924|\n",
      "|[56.5341658080891...|97.7438964834685|93.01859207402507|\n",
      "|[56.741741124191,...|103.540488116788|94.25872494152011|\n",
      "|[56.7644564465812...|79.1743758333647| 94.3944348053943|\n",
      "|[56.7854343692644...|83.9930774713752|94.51976479115442|\n",
      "|[56.789386413216,...|95.3280876779566|94.54337578542001|\n",
      "|[56.8103172829116...|84.1706947685606|94.66842465896733|\n",
      "|[56.8560821293767...|97.3649783271705|94.94184103304801|\n",
      "|[57.1038694679138...| 93.506315903823|96.42221561919641|\n",
      "|[57.1373009574261...|99.1084992611307|96.62194788858224|\n",
      "|[57.2026600428674...|103.962705070983|97.01242760248707|\n",
      "|[57.2330564010914...|99.3712842598644|97.19402685809044|\n",
      "|[57.2581173592998...|101.714182141616|97.34375043095443|\n",
      "|[57.3130235163555...| 93.876437404092|  97.671780426386|\n",
      "|[57.3139027398949...|95.1390467981634|97.67703323789348|\n",
      "|[57.3977403653233...| 106.58756270741|98.17791068699947|\n",
      "+--------------------+----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = reg.evaluate(test_data)\n",
    "pred.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abe5cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.save('reg_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68a0fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "| Height|Gender|\n",
      "+-------+------+\n",
      "|172.343|  Male|\n",
      "+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame([(172.343, 'Male')], ['Height', 'Gender']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90bdcdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the saved model\n",
    "from pyspark.ml.regression import LinearRegressionModel\n",
    "load_model  = LinearRegressionModel.load('reg_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eb12430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----------------+\n",
      "|    Independent_feat|          Weight|       prediction|\n",
      "+--------------------+----------------+-----------------+\n",
      "|[54.8737275315254...|78.6066703120237|   83.09851043868|\n",
      "|[55.336492408949,...|88.3665825783999|85.86324155022302|\n",
      "|[55.6682021205121...|68.9825300912419|87.84499989944189|\n",
      "|[56.0786997324948...|94.4883740514904|90.29746674476783|\n",
      "|[56.4456850266095...|96.6402446637704|92.48997466750924|\n",
      "|[56.5341658080891...|97.7438964834685|93.01859207402507|\n",
      "|[56.741741124191,...|103.540488116788|94.25872494152011|\n",
      "|[56.7644564465812...|79.1743758333647| 94.3944348053943|\n",
      "|[56.7854343692644...|83.9930774713752|94.51976479115442|\n",
      "|[56.789386413216,...|95.3280876779566|94.54337578542001|\n",
      "|[56.8103172829116...|84.1706947685606|94.66842465896733|\n",
      "|[56.8560821293767...|97.3649783271705|94.94184103304801|\n",
      "|[57.1038694679138...| 93.506315903823|96.42221561919641|\n",
      "|[57.1373009574261...|99.1084992611307|96.62194788858224|\n",
      "|[57.2026600428674...|103.962705070983|97.01242760248707|\n",
      "|[57.2330564010914...|99.3712842598644|97.19402685809044|\n",
      "|[57.2581173592998...|101.714182141616|97.34375043095443|\n",
      "|[57.3130235163555...| 93.876437404092|  97.671780426386|\n",
      "|[57.3139027398949...|95.1390467981634|97.67703323789348|\n",
      "|[57.3977403653233...| 106.58756270741|98.17791068699947|\n",
      "+--------------------+----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pred using load model\n",
    "new_pred = load_model.evaluate(test_data)\n",
    "new_pred.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06b925ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+----------------+\n",
      "|   Height|Gender|GenderMale|Independent_feat|\n",
      "+---------+------+----------+----------------+\n",
      "|172.34343|  Male|       1.0| [172.34343,1.0]|\n",
      "+---------+------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.feature import StringIndexerModel, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegressionModel\n",
    "Height = 172.34343\n",
    "Gender = 'Male'\n",
    "\n",
    "#create pyspark dataframe\n",
    "test_df = spark.createDataFrame([(Height, Gender)], ['Height', 'Gender'])\n",
    "\n",
    "\n",
    "indexer_model = StringIndexerModel.load('string_indexer.model')\n",
    "assembler_model = VectorAssembler.load('feature_assembler.model')\n",
    "reg_model = LinearRegressionModel.load('reg_model.model')\n",
    "\n",
    "#convert the gender using indexer\n",
    "indexed_test_df = indexer.transform(test_df)\n",
    "transformed_test_df = assembler_model.transform(indexed_test_df)\n",
    "transformed_test_df.show()\n",
    "# needed_data = transformed_test_df.select('Independent_feat')\n",
    "# print(needed_data.show())\n",
    "pred = reg_model.transform(transformed_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c466e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Height: double, Gender: string, GenderMale: double, Independent_feat: vector, prediction: double]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29a7acb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|      prediction|\n",
      "+----------------+\n",
      "|804.275351400699|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.select('prediction').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pyspark",
   "language": "python",
   "name": "venv_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
